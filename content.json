{"meta":{"title":"张果果的博客","subtitle":"","description":"","author":"张果果的博客","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"线程池","slug":"线程池","date":"2020-01-03T13:49:49.000Z","updated":"2020-03-29T12:36:33.233Z","comments":true,"path":"2020/01/03/线程池/","link":"","permalink":"http://yoursite.com/2020/01/03/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","excerpt":"线程池为什么要用线程池？ 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。","text":"线程池为什么要用线程池？ 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 实现Runnable接口和Callable接口的区别Runnable自Java 1.0以来一直存在，但Callable仅在Java 1.5中引入,目的就是为了来处理Runnable不支持的用例。Runnable 接口不会返回结果或抛出检查异常，但是Callable 接口可以。所以，如果任务不需要返回结果或抛出异常推荐使用 Runnable 接口，这样代码看起来会更加简洁。 工具类 Executors 可以实现 Runnable 对象和 Callable 对象之间的相互转换。（Executors.callable（Runnable task）或 Executors.callable（Runnable task，Object resule））。 执行execute()方法和submit()方法的区别是什么呢？ execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否； submit()方法用于提交需要返回值的任务。线程池会返回一个 Future 类型的对象，通过这个 Future 对象可以判断任务是否执行成功，并且可以通过 Future 的 get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用 get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。 如何创建线程池《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险 Executors 返回线程池对象的弊端如下： FixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。 方式一：通过构造方法实现 方式二：通过Executor 框架的工具类Executors来实现 我们可以创建三种类型的ThreadPoolExecutor： FixedThreadPool ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。 SingleThreadExecutor： 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。 CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。 ThreadPoolExecutor 类分析ThreadPoolExecutor 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。 123456789101112131415161718192021222324&#x2F;** * 用给定的初始参数创建一个新的ThreadPoolExecutor。 *&#x2F;public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;&#x3D; 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue &#x3D;&#x3D; null || threadFactory &#x3D;&#x3D; null || handler &#x3D;&#x3D; null) throw new NullPointerException(); this.corePoolSize &#x3D; corePoolSize; this.maximumPoolSize &#x3D; maximumPoolSize; this.workQueue &#x3D; workQueue; this.keepAliveTime &#x3D; unit.toNanos(keepAliveTime); this.threadFactory &#x3D; threadFactory; this.handler &#x3D; handler;&#125; ThreadPoolExecutor构造函数重要参数分析ThreadPoolExecutor 3 个最重要的参数： corePoolSize : 核心线程数线程数定义了最小可以同时运行的线程数量。 maximumPoolSize : 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。 workQueue: 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。 ThreadPoolExecutor其他常见参数: keepAliveTime:当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 keepAliveTime才会被回收销毁； unit : keepAliveTime 参数的时间单位。 threadFactory :executor 创建新线程的时候会用到。 handler :饱和策略。关于饱和策略下面单独介绍一下。 ThreadPoolExecutor 饱和策略ThreadPoolExecutor 饱和策略定义: 如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，ThreadPoolTaskExecutor 定义一些策略: ThreadPoolExecutor.AbortPolicy：抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 举个例子： Spring 通过 ThreadPoolTaskExecutor 或者我们直接通过 ThreadPoolExecutor 的构造函数创建线程池的时候，当我们不指定 RejectedExecutionHandler 饱和策略的话来配置线程池的时候默认使用的是 ThreadPoolExecutor.AbortPolicy。在默认情况下，ThreadPoolExecutor 将抛出 RejectedExecutionException 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 ThreadPoolExecutor.CallerRunsPolicy。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 ThreadPoolExecutor 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）","categories":[],"tags":[{"name":"Java JUC","slug":"Java-JUC","permalink":"http://yoursite.com/tags/Java-JUC/"}]},{"title":"并发容器","slug":"并发容器","date":"2020-01-03T13:49:31.000Z","updated":"2020-03-29T12:44:03.164Z","comments":true,"path":"2020/01/03/并发容器/","link":"","permalink":"http://yoursite.com/2020/01/03/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8/","excerpt":"JDK 提供的并发容器总结JDK 提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的 HashMap CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。","text":"JDK 提供的并发容器总结JDK 提供的这些容器大部分在 java.util.concurrent 包中。 ConcurrentHashMap: 线程安全的 HashMap CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector. ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。 BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。 ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。 ConcurrentHashMap我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 Collections.synchronizedMap() 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。 所以就有了 HashMap 的线程安全版本—— ConcurrentHashMap 的诞生。在 ConcurrentHashMap 中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。 ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构： JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 HashTable: JDK1.7的ConcurrentHashMap： JDK1.8的ConcurrentHashMap（TreeBin: 红黑二叉树节点 Node: 链表节点）： ConcurrentHashMap线程安全的具体实现方式/底层具体实现JDK1.7（上面有示意图）首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。 Segment 实现了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。 12static class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123;&#125; 一个 ConcurrentHashMap 里包含一个 Segment 数组。Segment 的结构和HashMap类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个HashEntry数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment的锁。 JDK1.8 （上面有示意图）ConcurrentHashMap取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(log(N))） synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。 CopyOnWriteArrayList在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内部数据，毕竟读取操作是安全的。 CopyOnWriteArrayList 是如何做到的？CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。 从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的 ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。 CopyOnWriteArrayList 读取操作的实现读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。 1234567891011private transient volatile Object[] array;public E get(int index) &#123; return get(getArray(), index);&#125;@SuppressWarnings(&quot;unchecked&quot;)private E get(Object[] a, int index) &#123; return (E) a[index];&#125;final Object[] getArray() &#123; return array;&#125; CopyOnWriteArrayList 写入操作的实现CopyOnWriteArrayList 写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。 1234567891011121314151617181920&#x2F;** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) *&#x2F;public boolean add(E e) &#123; final ReentrantLock lock &#x3D; this.lock; lock.lock();&#x2F;&#x2F;加锁 try &#123; Object[] elements &#x3D; getArray(); int len &#x3D; elements.length; Object[] newElements &#x3D; Arrays.copyOf(elements, len + 1);&#x2F;&#x2F;拷贝新数组 newElements[len] &#x3D; e; setArray(newElements); return true; &#125; finally &#123; lock.unlock();&#x2F;&#x2F;释放锁 &#125;&#125; ConcurrentLinkedQueueJava 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。 从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。 ConcurrentLinkedQueue 内部代码我们就不分析了，大家知道 ConcurrentLinkedQueue 主要使用 CAS 非阻塞算法来实现线程安全就好了。 ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的 ConcurrentLinkedQueue 来替代。 BlockingQueue上面我们己经提到了 ConcurrentLinkedQueue 作为高性能的非阻塞队列。下面我们要讲到的是阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是 BlockingQueue 提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。 ArrayBlockingQueueArrayBlockingQueue 是 BlockingQueue 接口的有界队列实现类，底层采用数组来实现。ArrayBlockingQueue 一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。 ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的 ArrayBlockingQueue，可采用如下代码： 1private static ArrayBlockingQueue&lt;Integer&gt; blockingQueue &#x3D; new ArrayBlockingQueue&lt;Integer&gt;(10,true); LinkedBlockingQueueLinkedBlockingQueue 底层基于单向链表实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足 FIFO 的特性，与 ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建 LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于 Integer.MAX_VALUE。 ConcurrentSkipListMap为了引出 ConcurrentSkipListMap，先带着大家简单理解一下跳表。 对于一个单链表，即使链表是有序的，如果我们想要在其中查找某个数据，也只能从头到尾遍历链表，这样效率自然就会很低，跳表就不一样了。跳表是一种可以用来快速查找的数据结构，有点类似于平衡树。它们都可以对元素进行快速的查找。但一个重要的区别是：对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。这样，在高并发环境下，你就可以拥有更好的性能。而就查询的性能而言，跳表的时间复杂度也是 O(logn) 所以在并发数据结构中，JDK 使用跳表来实现一个 Map。 )4[95T1)M0PCP.png) 使用跳表实现 Map 和使用哈希算法实现 Map 的另外一个不同之处是：哈希并不会保存元素的顺序，而跳表内所有的元素都是排序的。因此在对跳表进行遍历时，你会得到一个有序的结果。所以，如果你的应用需要有序性，那么跳表就是你不二的选择。JDK 中实现这一数据结构的类是 ConcurrentSkipListMap。","categories":[],"tags":[{"name":"Java JUC","slug":"Java-JUC","permalink":"http://yoursite.com/tags/Java-JUC/"}]},{"title":"Java并发进阶","slug":"Java并发进阶","date":"2020-01-03T12:13:22.000Z","updated":"2020-03-29T12:44:13.004Z","comments":true,"path":"2020/01/03/Java并发进阶/","link":"","permalink":"http://yoursite.com/2020/01/03/Java%E5%B9%B6%E5%8F%91%E8%BF%9B%E9%98%B6/","excerpt":"synchronized 关键字synchronized 关键字的了解synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。","text":"synchronized 关键字synchronized 关键字的了解synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。 怎么使用 synchronized 关键字synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！ 双重校验锁实现对象单例（线程安全） 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton uniqueInstance; private Singleton() &#123; &#125; public static Singleton getUniqueInstance() &#123; &#x2F;&#x2F;先判断对象是否已经实例过，没有实例化过才进入加锁代码 if (uniqueInstance &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;类对象加锁 synchronized (Singleton.class) &#123; if (uniqueInstance &#x3D;&#x3D; null) &#123; uniqueInstance &#x3D; new Singleton(); &#125; &#125; &#125; return uniqueInstance; &#125;&#125; 需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。 uniqueInstance = new Singleton(); 这段代码其实是分为三步执行： 123memory &#x3D; allocate();&#x2F;&#x2F;1.分配对象内存空间instance(memory); &#x2F;&#x2F;2.初始化对象instance &#x3D; memory; &#x2F;&#x2F;3.设置instance执行刚分配的内存地址，此时instance!&#x3D;null 步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化时允许的，如果3步骤提前于步骤2，但是instance还没有初始化完成。 使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。 synchronized 关键字的底层原理synchronized 关键字底层原理属于 JVM 层面。 ① synchronized 同步语句块的情况 1234567public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println(&quot;synchronized 代码块&quot;); &#125; &#125;&#125; 通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息 synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。 ② synchronized 修饰方法的的情况 12345public class SynchronizedDemo2 &#123; public synchronized void method() &#123; System.out.println(&quot;synchronized 方法&quot;); &#125;&#125; synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。 JDK1.6 之后的底层优化JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。 锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。 ①偏向锁 引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。 偏向锁的“偏”就是偏心的偏，它的意思是会偏向于第一个获得它的线程，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步！ ② 轻量级锁 倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。 轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！ ③ 自旋锁和自适应自旋 轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。 互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。 一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。自旋次数的默认值是10次，用户可以修改--XX:PreBlockSpin来更改。 另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。 ④ 锁消除 锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。 ⑤ 锁粗化 原则上，我们在编写代码的时候，总是推荐将同步块的作用范围限制得尽量小，——直在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。 Synchronized 和 ReenTrantLock 的对比① 两者都是可重入锁 “可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。 ② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。 ③ ReenTrantLock 比 synchronized 增加了一些高级功能 ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。 ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的 synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” 。 ④ 性能已不是选择标准 DK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。 volatile关键字Java内存模型Java 内存模型规定了所有的变量都存储在主内存，每条线程都有自己单独的工作内存，线程的工作内存中保存了被该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存，线程间变量值的传递均需要通过主内存来完成。 JMM关于同步的规定： 线程解锁前，必须把共享变量的值刷新回主内存 线程加锁前，必须读取主内存的最新值到自己的工作内存 加锁解锁时同一把锁 volatile是java虚拟机提供的轻量级的同步机制volatile 是 Java 虚拟机提供的最轻量级的同步机制。当一个变量被定义为 volatile 后，它将具备两种特性： 第一是保证此变量对所有线程的可见性，这里的「可见性」是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。普通变量则做不到这一点，需要通过主内存来在线程间传递数据。比如，线程 A 修改了一个普通的变量值，然后向主内存进行回写，另一条线程 B 在 A 线程回写完成之后再从主内存进行读写操作，新变量值才会对线程 B 可见。 第二是禁止指令重排优化。普通变量仅仅会保证方法的执行过程中所有依赖赋值结果的地方 能够获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执行顺序一致。因为在一个线程的方法执行过程中无法感知到这点，这也就是 Java 内存模型中描述的所谓的「线程内表现为串行的语义」。 synchronized 关键字和 volatile 关键字的区别 volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞 volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。 volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。 Atomic 原子类Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。所以，所谓原子类说简单点就是具有原子/原子操作特征的类。 JUC 包中的原子类是哪4类?基本类型 使用原子的方式更新基本类型 AtomicInteger：整形原子类 AtomicLong：长整型原子类 AtomicBoolean：布尔型原子类 数组类型 使用原子的方式更新数组里的某个元素 AtomicIntegerArray：整形数组原子类 AtomicLongArray：长整形数组原子类 AtomicReferenceArray：引用类型数组原子类 引用类型 AtomicReference：引用类型原子类 AtomicStampedReference：原子更新引用类型里的字段原子类 AtomicMarkableReference ：原子更新带有标记位的引用类型 对象的属性修改类型 AtomicIntegerFieldUpdater：原子更新整形字段的更新器 AtomicLongFieldUpdater：原子更新长整形字段的更新器 AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。 AtomicInteger 的使用1234567public final int get() &#x2F;&#x2F;获取当前的值public final int getAndSet(int newValue)&#x2F;&#x2F;获取当前的值，并设置新的值public final int getAndIncrement()&#x2F;&#x2F;获取当前的值，并自增public final int getAndDecrement() &#x2F;&#x2F;获取当前的值，并自减public final int getAndAdd(int delta) &#x2F;&#x2F;获取当前的值，并加上预期的值boolean compareAndSet(int expect, int update) &#x2F;&#x2F;如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）public final void lazySet(int newValue)&#x2F;&#x2F;最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。 1234567891011class AtomicIntegerTest &#123; private AtomicInteger count &#x3D; new AtomicInteger(); &#x2F;&#x2F;使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。 public void increment() &#123; count.incrementAndGet(); &#125; public int getCount() &#123; return count.get(); &#125;&#125; AtomicInteger 类的原理AtomicInteger 类的部分源码： 123456789101112&#x2F;&#x2F; setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）private static final Unsafe unsafe &#x3D; Unsafe.getUnsafe();private static final long valueOffset;static &#123; try &#123; valueOffset &#x3D; unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125;private volatile int value; AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。 CAS底层原理CAS全称呼Compare-And-Swap，它是一条CPU并发原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成数据不一致问题。 他的功能是判断内存某个位置的值是否为预期值，如果是则更改为新的值，这个过程是原子的。 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 &#x3D; this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。 CAS缺点 ** 循环时间长，开销大** 例如getAndAddInt方法执行，有个do while循环，如果CAS失败，一直会进行尝试，如果CAS长时间不成功，可能会给CPU带来很大的开销 只能保证一个共享变量的原子操作 对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性 ABA问题 ​ CAS算法实现一个重要前提需要去除内存中某个时刻的数据并在当下时刻比较并替换，那么在这个时间差类会导致数据的变化。 AtomicStampedReference：原子更新带有版本号的引用类型**。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题 CAS与synchronized的使用情景 简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 AQSSemaphore(信号量)-允许多个线程同时访问synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制 1234567891011121314151617181920212223public class SemaphoreDemo &#123; public static void main(String[] args) &#123; Semaphore semaphore &#x3D; new Semaphore(3);&#x2F;&#x2F;模拟三个停车位 for (int i &#x3D; 1; i &lt;&#x3D; 6; i++) &#123;&#x2F;&#x2F;模拟6部汽车 new Thread(() -&gt; &#123; try &#123; semaphore.acquire(); System.out.println(Thread.currentThread().getName() + &quot;\\t抢到车位&quot;); try &#123; TimeUnit.SECONDS.sleep(3);&#x2F;&#x2F;停车3s &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;\\t停车3s后离开车位&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); &#125; &#125;, &quot;Car &quot; + i).start(); &#125; &#125;&#125; CountDownLatch（倒计时器）CountDownLatch 的三种典型用法① 某一线程在开始运行前等待 n 个线程执行完毕。将 CountDownLatch 的计数器初始化为 n ：new CountDownLatch(n)，每当一个任务线程执行完毕，就将计数器减 1 countdownlatch.countDown()，当计数器的值变为 0 时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 ② 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的 CountDownLatch 对象，将其计数器初始化为 1 ：new CountDownLatch(1)，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为 0，多个线程同时被唤醒。 ③ 死锁检测：一个非常方便的使用场景是，你可以使用 n 个线程访问共享资源，在每次测试阶段的线程数目是不同的，并尝试产生死锁。 CountDownLatch主要有两个方法，当一个或多个线程调用await()方法时，调用线程会被阻塞。其他线程调用countDown()方法会将计数器减1，当计数器的值变为0时，因调用await()方法被阻塞的线程才会被唤醒，继续执行 12345678910111213141516public class CountDownLatchDemo &#123; public static void main(String[] args) throws InterruptedException &#123; countDownLatchTest(); &#125; public static void countDownLatchTest() throws InterruptedException &#123; CountDownLatch countDownLatch &#x3D; new CountDownLatch(6); for (int i &#x3D; 1; i &lt;&#x3D; 6; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName()+&quot;\\t被灭&quot;); countDownLatch.countDown(); &#125;, CountryEnum.forEach_CountryEnum(i).getRetMessage()).start(); &#125; countDownLatch.await(); System.out.println(Thread.currentThread().getName()+&quot;\\t&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;秦统一&quot;); &#125;&#125; CountDownLatch 的不足CountDownLatch 是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当 CountDownLatch 使用完毕后，它不能再次被使用。 CyclicBarrier(循环栅栏)可循环（Cyclic）使用的屏障。让一组线程到达一个屏障（也可叫同步点）时被阻塞，知道最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CycliBarrier的await()方法 CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。 123456789101112131415161718192021222324public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; cyclicBarrierTest(); &#125; public static void cyclicBarrierTest() &#123; CyclicBarrier cyclicBarrier &#x3D; new CyclicBarrier(7, () -&gt; &#123; System.out.println(&quot;&#x3D;&#x3D;&#x3D;&#x3D;召唤神龙&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;); &#125;); for (int i &#x3D; 1; i &lt;&#x3D; 7; i++) &#123; final int tempInt &#x3D; i; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot;\\t收集到第&quot; + tempInt + &quot;颗龙珠&quot;); try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125;, &quot;&quot; + i).start(); &#125; &#125;&#125; 对于CountDownLatch来说，重点是“一个线程（多个线程）等待”，而其他的N个线程在完成“某件事情”之后，可以终止，也可以等待。而对于CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。 CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。 ReentrantLock 和 ReentrantReadWriteLockReentrantLock 和 synchronized 的区别在上面已经讲过了这里就不多做讲解。另外，需要注意的是：读写锁 ReentrantReadWriteLock 可以保证多个线程可以同时读，所以在读操作远大于写操作的时候，读写锁就非常有用了。 ThreadLocalThreadLocal简介通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。如果想实现每一个线程都有自己的专属本地变量该如何解决呢？ JDK中提供的ThreadLocal类正是为了解决这样的问题。 ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。 如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是ThreadLocal变量名的由来。他们可以使用 get（） 和 set（） 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。 ThreadLocal原理从 Thread类源代码入手。 123456789public class Thread implements Runnable &#123; ......&#x2F;&#x2F;与此线程有关的ThreadLocal值。由ThreadLocal类维护ThreadLocal.ThreadLocalMap threadLocals &#x3D; null;&#x2F;&#x2F;与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护ThreadLocal.ThreadLocalMap inheritableThreadLocals &#x3D; null; ......&#125; 从上面Thread类 源代码可以看出Thread 类中有一个 threadLocals 和 一个 inheritableThreadLocals 变量，它们都是 ThreadLocalMap 类型的变量,我们可以把 ThreadLocalMap 理解为ThreadLocal 类实现的定制化的 HashMap。默认情况下这两个变量都是null，只有当前线程调用 ThreadLocal 类的 set或get方法时才创建它们，实际上调用这两个方法的时候，我们调用的是ThreadLocalMap类对应的 get()、set()方法。 ThreadLocal类的set()方法 1234567891011public void set(T value) &#123; Thread t &#x3D; Thread.currentThread(); ThreadLocalMap map &#x3D; getMap(t); if (map !&#x3D; null) map.set(this, value); else createMap(t, value);&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 最终的变量是放在了当前线程的 ThreadLocalMap 中，并不是存在 ThreadLocal 上，ThreadLocal 可以理解为只是ThreadLocalMap的封装，传递了变量值。ThrealLocal 类中可以通过Thread.currentThread()获取到当前线程对象后，直接通过getMap(Thread t)可以访问到该线程的ThreadLocalMap对象。 每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为key的键值对。 比如我们在同一个线程中声明了两个 ThreadLocal 对象的话，会使用 Thread内部都是使用仅有那个ThreadLocalMap 存放数据的，ThreadLocalMap的 key 就是 ThreadLocal对象，value 就是 ThreadLocal 对象调用set方法设置的值。 ThreadLocal 内部维护的是一个类似 Map 的ThreadLocalMap 数据结构，key 为当前对象的 Thread 对象，值为 Object 对象。 ThreadLocal 内存泄露问题ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法","categories":[],"tags":[{"name":"Java JUC","slug":"Java-JUC","permalink":"http://yoursite.com/tags/Java-JUC/"}]},{"title":"Java并发基础","slug":"Java并发基础","date":"2020-01-02T13:12:02.000Z","updated":"2020-03-29T12:44:29.875Z","comments":true,"path":"2020/01/02/Java并发基础/","link":"","permalink":"http://yoursite.com/2020/01/02/Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80/","excerpt":"Java并发基础什么是线程和进程?何为进程?进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。","text":"Java并发基础什么是线程和进程?何为进程?进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。 在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。 何为线程?线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。 请简要描述线程与进程的关系,区别及优缺点)]~HZF$PAJ2.png) 一个进程中可以有多个线程，多个线程共享进程的堆和方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的*程序计数器*、虚拟机栈 和 **本地方法栈。 总结： 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。 程序计数器为什么是私有的?程序计数器主要有下面两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 程序计数器私有主要是为了线程切换后能恢复到正确的执行位置 虚拟机栈和本地方法栈为什么是私有的? 虚拟机栈： 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。 本地方法栈： 和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 ​ 为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。 堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 说说并发与并行的区别? 并发： 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)； 并行： 单位时间内，多个任务同时执行。 为什么要使用多线程呢?先从总体上来说： 从计算机底层来说： 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。 从当代互联网发展趋势来说： 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。 再深入到计算机底层来探讨： 单核时代： 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。 多核时代: 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。 使用多线程可能带来什么问题?并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁还有受限于硬件和软件的资源闲置问题。 什么是上下文切换?概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。 Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。 什么是线程死锁?如何避免死锁?多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。 )$MU~~0@WM_@(926L3.png) 123456789101112131415161718192021222324252627282930313233343536public class DeadLockDemo &#123; private static Object resource1 &#x3D; new Object();&#x2F;&#x2F;资源 1 private static Object resource2 &#x3D; new Object();&#x2F;&#x2F;资源 2 public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread().getName() + &quot;get resource1&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;waiting get resource2&quot;); synchronized (resource2) &#123; System.out.println(Thread.currentThread().getName() + &quot;get resource2&quot;); &#125; &#125; &#125;, &quot;线程 1&quot;).start(); new Thread(() -&gt; &#123; synchronized (resource2) &#123; System.out.println(Thread.currentThread().getName() + &quot;get resource2&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;waiting get resource1&quot;); synchronized (resource1) &#123; System.out.println(Thread.currentThread().getName() + &quot;get resource1&quot;); &#125; &#125; &#125;, &quot;线程 2&quot;).start(); &#125;&#125; Output 1234线程 1get resource1线程 2get resource2线程 1waiting get resource2线程 2waiting get resource1 学过操作系统的朋友都知道产生死锁必须具备以下四个条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 如何避免线程死锁?我们只要破坏产生死锁的四个条件中的其中一个就可以了。 破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 我们对线程 2 的代码修改成下面这样就不会产生死锁了。 1234567891011121314new Thread(() -&gt; &#123; synchronized (resource1) &#123; System.out.println(Thread.currentThread() + &quot;get resource1&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;); synchronized (resource2) &#123; System.out.println(Thread.currentThread() + &quot;get resource2&quot;); &#125; &#125;&#125;, &quot;线程 2&quot;).start(); 线程的生命周期和状态?Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态 新建（New）：创建后尚未启动的线程处于这种状态；运行（Runnable）：Runnable 包括了操作系统线程状态中的 Running 和 Ready，也就是处于此状态的线程有可能正在执行，也有可能正在等待着 CPU 为它分配执行时间；无限期等待（Waiting）：处于这种状态的线程不会被分配 CPU 执行时间，它们要等待被其它线程显式地唤醒；以下三种方法会让线程进入无限期等待状态：没有设置 TimeOut 参数的 Object.wait()；没有设置 TimeOut 参数的 Thread.join()；LockSupport.park()。限期等待（Timed Waiting）：处于这种状态的线程也不会被分配 CPU 执行时间，不过无需等待被其它线程显式地唤醒，在一定时间之后它们会由系统自动唤醒；以下方法会让线程进入限期等待状态：Thread.sleep()；设置了 TimeOut 参数的 Object.wait()；设置了 TimeOut 参数的 Thread.join()；LockSupport.parkNanos()；LockSupport.parkUntil()。阻塞（Blocked）：线程被阻塞了，「阻塞状态」和「等待状态」的区别是：「阻塞状态」在等待着获取一个排他锁，这个事件将在另一个线程放弃这个锁的时候发生；而「等待状态」则是在等待一段时间，或者唤醒动作的发送。在程序等待进入同步区域时，线程将进入这种状态；结束（Terminated）：线程已经结束执行。 sleep() 方法和 wait() 方法区别和共同点? 两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。 两者都可以暂停线程的执行。 Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。 wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。 总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。","categories":[],"tags":[{"name":"Java JUC","slug":"Java-JUC","permalink":"http://yoursite.com/tags/Java-JUC/"}]}],"categories":[],"tags":[{"name":"Java JUC","slug":"Java-JUC","permalink":"http://yoursite.com/tags/Java-JUC/"}]}